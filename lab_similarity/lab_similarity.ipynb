{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Welcome to lab_similarity!\n",
    "\n",
    "We are half way done with Data Science DISCOVERY this semester!! Hopefully at this point, you've come to know a few things about your groupmates in your lab section through working together on the labs. But, have you ever wondered if there is someone very similar to you in the class that you haven't had the chance to get to know yet? In this lab you will find your in-class doppelganger or your \"Stat 107 Twin\". With the power of data science, you'll learn more about your peers than ever before by anaylzing the `Hello` dataset!\n",
    "\n",
    "To do this, you will:\n",
    "- Use Python to work with categorical and numeric data\n",
    "- Practice using conditionals in if-statements\n",
    "- Design and implement your own functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 0: Your Group!\n",
    "Edit the next Python cell to add information about who you're working within your lab section:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First, meet your CAs and TA if you haven't already!\n",
    "# ...first name is enough, we'll know who they are! :)\n",
    "ta_name = \"\"\n",
    "ca1_name = \"\"\n",
    "ca2_name = \"\"\n",
    "\n",
    "\n",
    "# Also, make sure to meet your team for this lab! Find out their name, what major they're in,\n",
    "# and learn something new about them that you never knew before!\n",
    "partner1_name = \"\"\n",
    "partner1_netid = \"\"\n",
    "partner1_major = \"\"\n",
    "\n",
    "partner2_name = \"\"\n",
    "partner2_netid = \"\"\n",
    "partner2_major = \"\"\n",
    "\n",
    "partner3_name = \"\"\n",
    "partner3_netid = \"\"\n",
    "partner3_major = \"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Dataframe Setup\n",
    "\n",
    "For the first part of our lab, we'll be using the \"Hello\" dataset one more time. We need to:\n",
    "- Import the proper libraries\n",
    "- Check a few rows in the dataframe\n",
    "- Check if the dataframe has any blank responses"
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1d75e2264482750",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 1.1: Import libraries and data\n",
    "\n",
    "Import everything you need for the lab. We will need `pandas` (as `pd`) and `matplotlib.pyplot` (as `plt`). For now, we'll only need pandas!  As in past labs, `hello.csv` should be in the same directory as this lab. Load it onto a dataframe called `df`.  Then, randomly sample and print 5 rows from the dataframe to see what our data looks like."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import pandas\n",
    "...\n",
    "\n",
    "# Load the dataframe and print out 5 random rows!\n",
    "df = ...\n",
    "..."
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-193e1aa1a2845076",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 0 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(len(df) == 284), \"The dataframe does not appear to have correct dataset loaded\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4630e717d7a78a09",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 1.2 Check for NAs\n",
    "\n",
    "Before we find our Stat 107 twins, we have to deal with missing values! The function below checks if there are any blank responses, which pandas encodes as \"NaN\" (Not a Number). If there are, the function prints all the cells that are in a row or column with an NaN. Otherwise, it returns `None` and prints a string that says: \"This dataframe has no NAs\". `None` is a special data type that represents a null value or no value at all. Once you're done writing the function, apply it to our dataframe, name the **return** value `df_na`, and print it.\n",
    "\n",
    "**More Details:** You can use **df.isnull().values.any()** to check a whole dataframe for NAs. \n",
    "\n",
    "**df.isnull().any()** will check each row or column for NAs, depending on what value you choose for the function parameter *axis*, and return a list of booleans.\n",
    "\n",
    "Just like with single rows/columns, you can use *df.loc[L1,L2]*, where L1 and L2 are lists of booleans, to get all the cells where the row *and* column meet a condition."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Here is a function that checks a dataframe for NAs\n",
    "def checkNAs(df):\n",
    "    if df.isnull().values.any():\n",
    "        return df.loc[df.isnull().any(axis=1),df.isnull().any()]\n",
    "    else:\n",
    "        print(\"This dataframe has no NAs\")\n",
    "        return None\n",
    "\n",
    "# Use the function to create a new dataframe of rows that have NAs called `df_na`\n",
    "df_na = ...\n",
    "df_na\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 1.2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert set(df_na.columns) == {'Name', 'Major', 'Computer', 'Holes In Straw', 'Statistics Courses',\n",
    "       'Study Hours Per Week', 'Shoe Number',\n",
    "       'How many different people (including each person in group chats!) did you text yesterday?',\n",
    "       'Introvert, extrovert, ambivert?'}, \"These are not the correct NA columns\"\n",
    "assert set(df_na.index)=={17, 30, 43, 59, 65, 118, 143, 187, 189, 200, 232, 269}, \"These are not the correct NA rows\"\n",
    "assert checkNAs(df[\"Year\"])==None, \"Make sure dataframes with no NAs return None\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 1.3: Dealing with NAs\n",
    "❓ **Individual Reflection Question** ❓ As a Data Scientist, we need to think about how to handle missing values.  One possible way to deal with them is to fill them all with 0s. What are some dangers to doing this? Also, what are some reasons you may want to deal with blank responses this way?  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Replace this text with your response.]* "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Group Discussion:** Discuss with your group: what are other ways for dealing with missing values? What is good about these ways and what is bad about them?  How does the sample space and goal (finding similarity) affect your response?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2 - Numerical vs. Categorical Data\n",
    "\n",
    "In order to find your Stat 107 Twin, it's important that we first identify the different types of data that we have in our dataset.\n",
    "\n",
    "**Numerical (or Quantitative) Data** is any type of data that can be expressed through numbers instead of descriptions. They can have an order, you can perform mathematical operations on them, etc. It makes sense to perform arithmetic on numeric data. The number of shoes a person owns is an example of a numeric variable.\n",
    "\n",
    "**Categorical (or Qualitative) Data** is any type of data that can be placed into categories using names or groups. Some categorical variables can take numerical values (like zip codes or your social security number), however, mathematical operations like adding them together would be odd. The type of phone you have is an example of a categorical variable.\n",
    "\n",
    "To keep things simple, we will categorize all of our columns as either categorical or numeric.  Run the code below to get the column names of all the categorical columns."
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b74977570d144bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical_cols = df.select_dtypes(exclude=\"number\").columns\n",
    "categorical_cols"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.1 Get dataframe with just categorical columns\n",
    "\n",
    "Using the names generated above, create a new dataframe `df_categorical` with all the categorical columns and print a random sample of 5 rows."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_categorical = ...\n",
    "..."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 2.1 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(len(categorical_cols) == 9), \"The list of numeric columns seems to have an incorrect number of elements\"\n",
    "assert(df_categorical.shape[0] == 284), \"The dataframe doesn't have the right number of rows\"\n",
    "assert(df_categorical.shape[1] == 9), \"The dataframe doesn't have the right number of columns\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.2 Get a dataframe with just numeric columns\n",
    "\n",
    "Using the list generated above, get all the names for numeric columns `numcols`, i.e. all the other columns. Then make a new dataframe `df_numeric` with all the numeric columns and print a random sample of 5 rows."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "numcols = ...\n",
    "df_numeric = ...\n",
    "..."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 2.2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(len(numcols) == 22), \"The list of numeric columns seems to have an incorrect number of elements\"\n",
    "assert(df_numeric.shape[0] == 284), \"The dataframe doesn't have the right number of rows\"\n",
    "assert(df_numeric.shape[1] == 22), \"The dataframe doesn't have the right number of columns\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.3 Visualizing Numeric Data\n",
    "\n",
    "Plot the histograms for each columns in `df_numeric`\n",
    "\n",
    "- If needed: In `df.hist`, use **`figsize=(30, 40)`** as an optional argument passed to `hist` to make your figure bigger."
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ae8425133ce9746b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot the histogram for each column in df_nueric\n",
    "\n",
    "..."
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-320d0db0b0449486",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.4 Visualize \"Year\" \n",
    "\n",
    "To visualize the categorical data we will be using a bar plot.  However, we first need to convert our DataFrame with the categorical data into counts for each value.  To do this, we can use [`Series.value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) on a column of data.\n",
    "\n",
    "Let's see how this works.  Select just the `[\"Year\"]` from `df_categorical` and apply `.value_counts()`.  Then, in the next cell, use that data to make a bar plot using `.plot.bar()`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use `.value_counts()` to find the values counts of data about [\"Year\"]\n",
    "value_counts = ...\n",
    "value_counts"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a70b687d4464dd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Now, use `value_counts` to plot a bar chart:\n",
    "..."
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a11d63567013a46",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.5 Visualize all Categorical Data\n",
    "\n",
    "Finally, repeat this process for the columns in `df_categorical` using a for loop. You can use pyplot's `plt.show()` to display all the plots."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for column in categorical_cols:\n",
    "    import matplotlib. pyplot as plt\n",
    "    df_categorical[column].value_counts().plot.bar(title=column)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.5 Handling Different Variable Types\n",
    "\n",
    "❓ **Group Discussion and Individual Reflection** ❓ It's important to note that data represented with numbers aren't always categorized as quantitative (such as zip code or social security number). Looking at the graphs we generated, what are some examples of numeric data that might work better as categories or categorical data that could make sense to order? Can you think of other examples of data that is technically numbers, but would be categorized as categorical? Write down some highlights of your discussion below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Replace this text with your response.]*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 2.6 Clean up the Data\n",
    "\n",
    "Now that you know what the data looks like and what types of columns we are dealing with in this dataset, you must decided what to do with the NAs in the dataset. This decision is up to you as a data scientist!  There is no definite right answer. Functions like `fillna()`and `df.replace()` may be helpful. Use the `checkNAs()` function we made earlier to make sure all the NAs have been dealt with. Then, briefly explain what you did and why in the text box below.\n",
    "\n",
    "**HINT:** (double-click this cell to see it): <span style=\"color:#ffffff00\">One possible way to do this is to treat categorical and numeric NAs separately. For categorical columns, not responding coud be its own category indicated by some string like \"Blank\". For numeric columns, NAs could be represented by a central value like the mean, median, or an extreme value well outside the values of possible answers.</span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "...\n",
    "..."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Replace this text with your response.]*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Now, Time to Find Yourself\n",
    "\n",
    "You cannot find people you are compatible with before finding yourself... literally! \n",
    "\n",
    "### Puzzle 3.1: Find Yourself\n",
    "\n",
    "In the following cell, write the Python code to create a DataFrame with only yourself:"
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-502c0d7f6ea29b5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "myrow = ...\n",
    "myrow"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04bc136da68bc695",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 3.1 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(len(myrow) == 1), \"The row of yourself is not correctly set\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7b019251e3c71d1f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataFrame with one row vs. a Series\n",
    "\n",
    "In `pandas`, there are three major data structures we will be using:\n",
    "\n",
    "- A **DataFrame** is similar to an Excel sheet.  It contains zero or more rows and zero or more columns.  It can contain up to an unlimited number of rows and columns and is the basic data structure we will work with in Data Science Discovery\n",
    "\n",
    "- A **GroupBy** is a grouping of rows within a DataFrame.  This \"three dimensional data\" requires us to use `agg` to reduce it back down to a **DataFrame**.\n",
    "\n",
    "- A **Series** is a single row or column with zero or more values (columns).  You can think of a DataFrame as a collection of **Series** objects.  When you select a single column, you may have noticed that `pandas ` automatically outputs a **Series** object. When we deal with a single row, however, we will usually need to manually convert it to a **Series** instead of a **one row DataFrame**.\n",
    "\n",
    "#### Converting between types\n",
    "\n",
    "The `pandas` library makes it easy to convert between a **Series**, **DataFrame**, and **GroupBy**.\n",
    "\n",
    "![image.png](img/datatypes.png)\n",
    "\n",
    "Expressed as a list:\n",
    "\n",
    "- From a **Series** (`row`) to a **DataFrame**\n",
    "  * `row.to_frame()`\n",
    "- From a **DataFrame** (`df`) to a **GroupBy**:\n",
    "  * `df.groupby(by='columnName')` *-- (You know this already!)*\n",
    "\n",
    "- From a **GroupBy** (`group`) to a **DataFrame**:\n",
    "  * `df.agg( function )` *-- (You know this already!)*\n",
    "- From a **DataFrame** (`df`) to a **Series**:\n",
    "  * `df.squeeze()`, if the DataFrame has one row\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "### Puzzle 3.2: Transform your row into a Series\n",
    " \n",
    "Using the correct function from above, transform the row containing only you from a one-row DataFrame into a Series.  Make sure the Series is named `myrow` (this will match up with code we provide you with later):"
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe30a545161f7fbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "..."
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c946526ed7a65cd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 3.2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(type(myrow) == pd.core.series.Series), \"You did not successfully transform myrow's type into series\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-13e6051988c8bf2d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4 - Create a similarity function\n",
    "\n",
    "The first step to finding who is the most similar to you is to create a **function** that will generate a similarity value for each person (or row). Unlike `sum`, `count`, or other functions, Python does not provide us a **function** that does this.  Instead, we need to write it ourselves. 😞\n",
    "\n",
    "Using what you learned in lecture, let's write this function!\n",
    "\n",
    "### Planning it out\n",
    "Before starting to code, think about the **algorithm** you would like to use:\n",
    "\n",
    "1. Go through each person.\n",
    "2. Compare their responses to each question with yours.\n",
    "3. Calculate and record a \"similarity score\". based on those comparisons.\n",
    "\n",
    "Also, think about what **parameters** (input) and **return** (output) you want your function to have:\n",
    "\n",
    "*Input:* - the row you want the similarity score for, the row you are comparing against (your row)\n",
    "\n",
    "*Output:* - a numeric score representing the similarity between a row and the row being compared against\n",
    "\n",
    "### Output Details\n",
    "For each column, we want the score scale to be between 0 and 1, with 1 representing exact matches. So, if a row is the exact same as the one we're comparing it against it should have a score equal to the number of columns.\n",
    "\n",
    "For a measure of ***closeness*** between values for the numerical data we'll use the following formula:\n",
    "\n",
    "$1 -$ ( $|actual - desired|$ / $(maxColumnValue - minColumnValue)$ )\n",
    "\n",
    "### Helpful tips\n",
    "- Remember that you can loop through the columns of a dataframe\n",
    "- Treat numeric data and categorical data differently\n",
    "- Have a plan to test for if a column is all 0's\n"
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-553f54db699dd66f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 4.1 Planning it out\n",
    "\n",
    "Briefly describe any special cases you want to take into account or any weights or values you want to use for specific columns in the text box below. If there are none, state that instead. *(This part is completely up to you, just make sure it makes sensce and your code matches what you describe.)*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Replace this text with your response.]*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 4.2 Write the function\n",
    "\n",
    "Now that everything has been thoroughly planned out, you're ready to write the function!  This is the most complicated part of the lab, so take your time :)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def similarity(row, myrow):\n",
    "    score = 0\n",
    "    \n",
    "    for column in df:\n",
    "        ...\n",
    "    return score"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51500f7d58876da9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 4.3 Testing the function\n",
    "\n",
    "Part of writing a function is making sure it does what you want it to. Test this function by checking how similar you are with yourself. Check to make sure the output is what you would expect. You can also use this space to test any special cases you would like to check."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First test this function by checking how similar you are with yourself.\n",
    "# The expected result will be a number equal to the number of columns you checked:\n",
    "...\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5 - Using the Function\n",
    "\n",
    "### The Tuple Datatype\n",
    "\n",
    "Previously, we encountered several datatypes for storing multiple pieces of information: **DataFrame**, **List**, and most recently in `lab_simulation` **Dictionary**. You may remember changing these structures after creating them, like adding a new column to a **DataFrame** to store GPA values or appending to a **List** to gather simulation outputs. The **Tuple** datatype is similar to a **List**, but once you make it, you can't change it. This makes **Tuples** safer for passing arguments into functions and outputting more than one value from a function. A **Tuple** like a list with parentheses instead of square brackets: `(<thing1>,<thing2>,...)`. A single item tuple looks like this: `(<thing>,)`.\n",
    "\n",
    "### Puzzle 5.1 Making an argument tuple\n",
    "\n",
    "We will use `df.apply()` to apply our `similarity()` function to each row in our dataframe but we need to also pass `myrow` as a second argument to the function. To do this, we need to put that value into a one element tuple. Make this single item tuple below and name it `args`."
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1031a2762eed61e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "args = ...\n",
    "args"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Puzzle 5.2 - Get similarity for all rows\n",
    "\n",
    "Use `df.apply()` to apply your `similarity` function to each row of the dataframe. Make sure your input is correct so that it will run the `similarity` function you defined earlier across all rows, comparing them with `myrow`. If you're not sure what arguments/inputs to use, the documentation for `apply()` can be found [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html). Assign the new values to a new column in `df` and name the column `\"similarity\"`.\n",
    "\n",
    "**HINT:** (double-click this cell to see it): \n",
    "<span style=\"color:#ffffff00\"> Aside from the function name, you will also need the **args=** and **axis=** arguments</span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[\"similarity\"] = ..."
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ddb7d2fa7a20c87",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 5 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(df.shape[1] >= 32), \"You need to apply your similarity function to your dataframe\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec38b4dade899048",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Puzzle 5.3 - Find your twin!\n",
    "\n",
    "Your last column in your DataFrame is a **metric** (a measurement) of how similar you are to everyone else in the class!\n",
    "\n",
    "Use your **cheat sheet** (link: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) to find how to sort a DataFrame where the most similar person is on top.  Store that sorted DataFrame in `df_twins`.\n",
    "\n",
    "- You should be most similar to yourself (you will always match yourself)!  *If this is not the case, you did something wrong and should double-check all of your steps up to this point.*"
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b60caa666e942962",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_twins = ...\n",
    "df_twins"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f540c719178869e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## == TEST CASES for Puzzle 6 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs with the success message as your output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert( df_twins.head(1).squeeze()[\"Name\"] == myrow[\"Name\"] ), \"You must be most similar to yourself.\"\n",
    "\n",
    "## == SUCCESS MESSAGE ==\n",
    "# You will only see this message (with the emoji showing) if you passed all test cases:\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ],
   "outputs": [],
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d17c8bf547ab9ea7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finale!\n",
    "\n",
    "You're almost done -- congratulations!\n",
    "\n",
    "You need to do two more things:\n",
    "\n",
    "1.  Save your work. To do this, go to File -> Save All\n",
    "\n",
    "2.  After you have saved, exit this notebook and follow the webpage instructions to commit this lab to your Git repository!"
   ],
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc56fb367aec1907",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}